{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cfc39707",
      "metadata": {},
      "source": [
        "# Jupyter Notebook for `train_model.py`\n",
        "This notebook explains and executes the logic of the `train_model.py` script. Each section will describe the purpose of the code and walk through the implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e84911",
      "metadata": {},
      "source": [
        "## Imports and Setup\n",
        "These imports include FastAI for vision tasks, PyTorch for model and loss definitions, and utility modules like `sklearn` and `collections` for metrics and data handling. Also the path for the training and validation dataset is defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8da665c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n",
        "import multiprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "from fastai.learner import Metric\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from fastai.learner import Metric\n",
        "from collections import defaultdict\n",
        "\n",
        "data_path = Path(\"../../images/dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4838de4",
      "metadata": {},
      "source": [
        "## `BalancedLabelDistanceLoss` Class\n",
        "This custom loss penalizes predictions based on the distance between predicted and true class indices, weighted by class frequency to mitigate class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9ecd941",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class BalancedLabelDistanceLoss(nn.Module):\n",
        "    def __init__(self, class_counts, epsilon=1e-6):\n",
        "        super().__init__()\n",
        "        self.register_buffer('weights', 1.0 / (torch.tensor(class_counts).float() + epsilon))\n",
        "        self.weights = self.weights / self.weights.sum() * len(class_counts)\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        probs = F.softmax(preds, dim=1)\n",
        "        class_indices = torch.arange(preds.size(1), device=preds.device).float()\n",
        "        expected = (probs * class_indices).sum(dim=1)\n",
        "\n",
        "        error = (expected - targets.float()).pow(2)\n",
        "\n",
        "        sample_weights = self.weights[targets]\n",
        "        return error * sample_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aafb1549",
      "metadata": {},
      "source": [
        "## `BalancedHybridLoss` Class\n",
        "Combines CrossEntropyLoss and the BalancedLabelDistanceLoss using a weighted alpha parameter. Helps to better capture both classification accuracy and class-distance sensitivity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f405e00",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class BalancedHybridLoss(nn.Module):\n",
        "    def __init__(self, class_counts, alpha=0.8):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
        "        self.label_distance = BalancedLabelDistanceLoss(class_counts)\n",
        "\n",
        "    def forward(self, preds, targets, **kwargs):\n",
        "        loss_ce = self.ce(preds, targets)\n",
        "        loss_ld = self.label_distance(preds, targets)\n",
        "        combined = self.alpha * loss_ce + (1 - self.alpha) * loss_ld\n",
        "\n",
        "        if kwargs.get('reduction', None) == 'none':\n",
        "            return combined\n",
        "        else:\n",
        "            return combined.mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b954be3",
      "metadata": {},
      "source": [
        "## `BalancedLabelDistance` Metric\n",
        "A custom metric to evaluate the average distance between predicted and actual labels per class. These average distances per class are added together to also get the average across all classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ecdf878",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class BalancedLabelDistance(Metric):\n",
        "    def __init__(self): self._name = 'balanced_label_distance'\n",
        "\n",
        "    def reset(self):\n",
        "        self.class_totals = defaultdict(float)\n",
        "        self.class_counts = defaultdict(int)\n",
        "\n",
        "    def accumulate(self, learn):\n",
        "        preds = learn.pred.argmax(dim=1)\n",
        "        targets = learn.y\n",
        "\n",
        "        for pred, target in zip(preds, targets):\n",
        "            error = abs(pred.item() - target.item())\n",
        "            self.class_totals[target.item()] += error\n",
        "            self.class_counts[target.item()] += 1\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        class_avg_distances = []\n",
        "        for cls in sorted(self.class_counts.keys()):\n",
        "            count = self.class_counts[cls]\n",
        "            if count > 0:\n",
        "                avg = self.class_totals[cls] / count\n",
        "                class_avg_distances.append(avg)\n",
        "        return sum(class_avg_distances) / len(class_avg_distances) if class_avg_distances else None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "665ae0fd",
      "metadata": {},
      "source": [
        "## Detailed Explanation of the main routine\n",
        "\n",
        "This section orchestrates the entire model training and evaluation pipeline using the FastAI library. \n",
        "\n",
        "### 1. Data Loading and Transformation\n",
        "Purpose: Load images from `train/` and `val/` folders and apply preprocessing.\n",
        "\n",
        "- Resize all images to 224x224\n",
        "- Apply image augmentations like flipping, zoom, warp, etc.\n",
        "- Normalize with ImageNet statistics\n",
        "- Use a batch size of 64\n",
        "- Shuffle training data for better generalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ff5682-cdc9-433c-865c-9c59241dbcaa",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "multiprocessing.freeze_support()\n",
        "\n",
        "dls = ImageDataLoaders.from_folder(\n",
        "        data_path,\n",
        "        train='train',\n",
        "        valid='val',\n",
        "        valid_pct=None,\n",
        "        item_tfms=Resize(224),\n",
        "        batch_tfms=aug_transforms(mult=1.5) + [Normalize.from_stats(*imagenet_stats)],\n",
        "        bs=64,\n",
        "        num_workers=0,\n",
        "        shuffle=True\n",
        "    )\n",
        "print(f\"Number of training batches: {len(dls.train)}\")   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6251d79a",
      "metadata": {},
      "source": [
        "### 2. Compute Class Counts\n",
        "Purpose: Count how many training samples exist for each class. This helps to create a balanced loss function so rare classes are not ignored.\n",
        "\n",
        "- Extract labels from folder names\n",
        "- Count number of samples per label\n",
        "- Fill in missing classes with count 1 to avoid division by zero\n",
        "- Store this in `class_counts`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5486d3fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_folder = data_path / 'train'\n",
        "train_labels = [int(path.parent.name) for path in train_folder.rglob('*') if path.is_file()]\n",
        "num_classes = len(set(train_labels))\n",
        "counts = Counter(train_labels)\n",
        "class_counts = [counts.get(i, 1) for i in range(num_classes)]\n",
        "print(\"Class counts:\", class_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26bb880b",
      "metadata": {},
      "source": [
        "### 3. Create Learner with Custom Loss and Metric\n",
        "Purpose: Set up the model training configuration using FastAI's Learner.\n",
        "\n",
        "- `resnet50`: Pretrained model used as a backbone\n",
        "- `BalancedHybridLoss`: Custom loss combining cross-entropy and label distance\n",
        "- `BalancedLabelDistance`: Custom metric tracking prediction distance from true labels\n",
        "- Callbacks:\n",
        "  - SaveModelCallback: Save best-performing model\n",
        "  - EarlyStoppingCallback: Stop early if no improvement\n",
        "  - ReduceLROnPlateau: Lower LR if validation loss stalls\n",
        "  - GradientClip: Prevent exploding gradients\n",
        "  - CSVLogger: Log metrics to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38bfdd24",
      "metadata": {},
      "outputs": [],
      "source": [
        "learn = vision_learner(dls, resnet50,\n",
        "    loss_func=BalancedHybridLoss(class_counts, alpha=0.35),\n",
        "    metrics=[\n",
        "        accuracy,\n",
        "        BalancedLabelDistance()\n",
        "    ],\n",
        "    cbs=[\n",
        "        SaveModelCallback(monitor='balanced_label_distance', comp=np.less, fname='best_model'),\n",
        "        EarlyStoppingCallback(monitor='valid_loss', comp=np.less, patience=5),\n",
        "        ReduceLROnPlateau(monitor='valid_loss', patience=2),\n",
        "        GradientClip(max_norm=1.0),\n",
        "        CSVLogger(fname='training_log.csv')\n",
        "    ])\n",
        "print(\"Created learner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed2e229f",
      "metadata": {},
      "source": [
        "### 4. Train and Fine-Tune Model\n",
        "Purpose: Fine-tune the model over 40 epochs. Uses transfer learning.\n",
        "\n",
        "- First few epochs train the head only\n",
        "- Then all layers are unfrozen and trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01aea27d",
      "metadata": {},
      "outputs": [],
      "source": [
        "learn.fine_tune(40)\n",
        "print(\"Fine-tuned model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e922e97",
      "metadata": {},
      "source": [
        "### 5. Evaluate Overall Accuracy\n",
        "Purpose: Check how well the model performs overall on validation data.\n",
        "\n",
        "- `get_preds()` returns predictions and labels\n",
        "- `accuracy_score` gives overall classification accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02d718a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "val_predictions, val_targets = learn.get_preds()\n",
        "val_accuracy = accuracy_score(val_targets, val_predictions.argmax(dim=1))\n",
        "print(f\"\\nValidation Accuracy: {val_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd88717b",
      "metadata": {},
      "source": [
        "### 6. Balanced Label Distance Evaluation\n",
        "Purpose: Measure the average distance between predicted and actual class indices.\n",
        "\n",
        "- For example, predicting class 4 when the true label is 5 is less bad than predicting class 1\n",
        "- This metric gives a more nuanced view of performance, especially in ordinal problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da485565",
      "metadata": {},
      "outputs": [],
      "source": [
        "class_totals = defaultdict(float)\n",
        "class_counts = defaultdict(int)\n",
        "for pred, target in zip(val_predictions.argmax(dim=1), val_targets):\n",
        "    dist = abs(pred.item() - target.item())\n",
        "    class_totals[target.item()] += dist\n",
        "    class_counts[target.item()] += 1\n",
        "class_avg_dists = []\n",
        "for cls in sorted(class_counts.keys()):\n",
        "    avg_dist = class_totals[cls] / class_counts[cls]\n",
        "    class_avg_dists.append(avg_dist)\n",
        "    print(f\"Class {cls}: Avg label distance = {avg_dist:.4f}\")\n",
        "balanced_distance = sum(class_avg_dists) / len(class_avg_dists)\n",
        "print(f\"\\nBalanced Label Distance (validation): {balanced_distance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d337989",
      "metadata": {},
      "source": [
        "### 7. Confusion Matrix and Per-Class Accuracy\n",
        "Purpose: Visualize which classes are confused with each other and calculate per-class accuracy.\n",
        "\n",
        "- Confusion matrix shows counts of true vs predicted labels\n",
        "- Per-class accuracy helps identify which labels are hardest to predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37908d2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "preds, targs = learn.get_preds(dl=learn.dls.valid)\n",
        "decoded = preds.argmax(dim=1)\n",
        "assert len(decoded) == len(targs), f\"Shape mismatch: {len(decoded)} vs {len(targs)}\"\n",
        "cm = confusion_matrix(targs.cpu(), decoded.cpu())\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=learn.dls.vocab)\n",
        "disp.plot(xticks_rotation=45, cmap='Blues')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nPer-class accuracy:\")\n",
        "cm = confusion_matrix(val_targets, val_predictions.argmax(dim=1))\n",
        "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
        "for cls, acc in zip(learn.dls.vocab, per_class_acc):\n",
        "    print(f\"{cls}: {acc:.4f}\")\n",
        "print(\"Evaluation completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "503c8374",
      "metadata": {},
      "source": [
        "### 8. Export the Trained Model\n",
        "Purpose: Save the trained model to disk as a `.pkl` file.\n",
        "\n",
        "- Can be loaded later for inference\n",
        "- Includes model weights, transforms, and label mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab4e7b25",
      "metadata": {},
      "outputs": [],
      "source": [
        "learn.remove_cb(CSVLogger)\n",
        "learn.export(\"road_quality_classifier.pkl\")\n",
        "print(\"Model saved successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9571c884-6647-4a1e-b591-70f37402e376",
      "metadata": {},
      "source": [
        "### Summary\n",
        "\n",
        "| Step | Purpose |\n",
        "|------|---------|\n",
        "| Data Loading | Load and preprocess image data |\n",
        "| Class Count | Adjust loss to balance rare vs common classes |\n",
        "| Learner Setup | Define model, loss, metrics, and training hooks |\n",
        "| Training | Fine-tune model using transfer learning |\n",
        "| Evaluation | Measure accuracy and custom distance metric |\n",
        "| Visualization | See how well each class is recognized |\n",
        "| Export | Save trained model for reuse |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

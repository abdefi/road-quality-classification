{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "cfc39707",
      "cell_type": "markdown",
      "source": "# Jupyter Notebook for `train_model.py`\nThis notebook explains and executes the logic of the `train_model.py` script. Each section will describe the purpose of the code and walk through the implementation.",
      "metadata": {}
    },
    {
      "id": "35e84911",
      "cell_type": "markdown",
      "source": "## Imports and Setup\nThese imports include FastAI for vision tasks, PyTorch for model and loss definitions, and utility modules like `sklearn` and `collections` for metrics and data handling. Also the path for the training and validation dataset is defined.",
      "metadata": {}
    },
    {
      "id": "d8da665c",
      "cell_type": "code",
      "source": "from fastai.vision.all import *\nimport multiprocessing\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.metrics import accuracy_score\nfrom fastai.learner import Metric\nimport numpy as np\nfrom collections import Counter\n\n\ndata_path = Path(\"dataset\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c4838de4",
      "cell_type": "markdown",
      "source": "## `BalancedLabelDistanceLoss` Class\nThis custom loss penalizes predictions based on the distance between predicted and true class indices, weighted by class frequency to mitigate class imbalance.",
      "metadata": {}
    },
    {
      "id": "f9ecd941",
      "cell_type": "code",
      "source": "\nclass BalancedLabelDistanceLoss(nn.Module):\n    def __init__(self, class_counts, epsilon=1e-6):\n        super().__init__()\n        self.register_buffer('weights', 1.0 / (torch.tensor(class_counts).float() + epsilon))\n        self.weights = self.weights / self.weights.sum() * len(class_counts)\n\n    def forward(self, preds, targets):\n        probs = F.softmax(preds, dim=1)\n        class_indices = torch.arange(preds.size(1), device=preds.device).float()\n        expected = (probs * class_indices).sum(dim=1)\n\n        error = (expected - targets.float()).pow(2)\n\n        sample_weights = self.weights[targets]\n        return error * sample_weights\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "aafb1549",
      "cell_type": "markdown",
      "source": "## `BalancedHybridLoss` Class\nCombines CrossEntropyLoss and the BalancedLabelDistanceLoss using a weighted alpha parameter. Helps to better capture both classification accuracy and class-distance sensitivity.",
      "metadata": {}
    },
    {
      "id": "6f405e00",
      "cell_type": "code",
      "source": "\nclass BalancedHybridLoss(nn.Module):\n    def __init__(self, class_counts, alpha=0.8):\n        super().__init__()\n        self.alpha = alpha\n        self.ce = nn.CrossEntropyLoss(reduction='none')\n        self.label_distance = BalancedLabelDistanceLoss(class_counts)\n\n    def forward(self, preds, targets, **kwargs):\n        loss_ce = self.ce(preds, targets)\n        loss_ld = self.label_distance(preds, targets)\n        combined = self.alpha * loss_ce + (1 - self.alpha) * loss_ld\n\n        if kwargs.get('reduction', None) == 'none':\n            return combined\n        else:\n            return combined.mean()\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0b954be3",
      "cell_type": "markdown",
      "source": "## `BalancedLabelDistance` Metric\nA custom metric to evaluate the average distance between predicted and actual labels per class. These average distances per class are added together to also get the average across all classes.",
      "metadata": {}
    },
    {
      "id": "2ecdf878",
      "cell_type": "code",
      "source": "\nfrom fastai.learner import Metric\nfrom collections import defaultdict\n\nclass BalancedLabelDistance(Metric):\n    def __init__(self): self._name = 'balanced_label_distance'\n\n    def reset(self):\n        self.class_totals = defaultdict(float)\n        self.class_counts = defaultdict(int)\n\n    def accumulate(self, learn):\n        preds = learn.pred.argmax(dim=1)\n        targets = learn.y\n\n        for pred, target in zip(preds, targets):\n            error = abs(pred.item() - target.item())\n            self.class_totals[target.item()] += error\n            self.class_counts[target.item()] += 1\n\n    @property\n    def value(self):\n        class_avg_distances = []\n        for cls in sorted(self.class_counts.keys()):\n            count = self.class_counts[cls]\n            if count > 0:\n                avg = self.class_totals[cls] / count\n                class_avg_distances.append(avg)\n        return sum(class_avg_distances) / len(class_avg_distances) if class_avg_distances else None\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "665ae0fd",
      "cell_type": "markdown",
      "source": "## Main Training and Evaluation Workflow\nThis section handles data loading, model training with the custom loss and metric, and evaluation including confusion matrix and per-class accuracy. A more detailed explaination follows after the code.",
      "metadata": {}
    },
    {
      "id": "b7ff5682-cdc9-433c-865c-9c59241dbcaa",
      "cell_type": "code",
      "source": "def main():\n    dls = ImageDataLoaders.from_folder(\n        data_path,\n        train='train',\n        valid='val',\n        valid_pct=None,\n        item_tfms=Resize(224),\n        batch_tfms=aug_transforms(mult=1.5) + [Normalize.from_stats(*imagenet_stats)],\n        bs=64,\n        num_workers=0,\n        shuffle=True\n    )\n    print(f\"Number of training batches: {len(dls.train)}\")\n\n    train_folder = data_path / 'train'\n    train_labels = [int(path.parent.name) for path in train_folder.rglob('*') if path.is_file()]\n    num_classes = len(set(train_labels))\n    counts = Counter(train_labels)\n    class_counts = [counts.get(i, 1) for i in range(num_classes)]\n    print(\"Class counts:\", class_counts)\n    learn = vision_learner(dls, resnet50,\n        loss_func=BalancedHybridLoss(class_counts, alpha=0.35),\n        metrics=[\n            accuracy,\n            BalancedLabelDistance()\n        ],\n        cbs=[\n            SaveModelCallback(monitor='balanced_label_distance', comp=np.less, fname='best_model'),\n            EarlyStoppingCallback(monitor='valid_loss', comp=np.less, patience=5),\n            ReduceLROnPlateau(monitor='valid_loss', patience=2),\n            GradientClip(max_norm=1.0),\n            CSVLogger(fname='training_log.csv')\n        ])\n    print(\"Created learner\")\n    learn.fine_tune(40)\n    print(\"Fine-tuned model\")\n\n    val_predictions, val_targets = learn.get_preds()\n    val_accuracy = accuracy_score(val_targets, val_predictions.argmax(dim=1))\n    print(f\"\\nValidation Accuracy: {val_accuracy:.4f}\")\n\n\n    class_totals = defaultdict(float)\n    class_counts = defaultdict(int)\n    for pred, target in zip(val_predictions.argmax(dim=1), val_targets):\n        dist = abs(pred.item() - target.item())\n        class_totals[target.item()] += dist\n        class_counts[target.item()] += 1\n    class_avg_dists = []\n    for cls in sorted(class_counts.keys()):\n        avg_dist = class_totals[cls] / class_counts[cls]\n        class_avg_dists.append(avg_dist)\n        print(f\"Class {cls}: Avg label distance = {avg_dist:.4f}\")\n    balanced_distance = sum(class_avg_dists) / len(class_avg_dists)\n    print(f\"\\nBalanced Label Distance (validation): {balanced_distance:.4f}\")\n\n\n    preds, targs = learn.get_preds(dl=learn.dls.valid)\n    decoded = preds.argmax(dim=1)\n    assert len(decoded) == len(targs), f\"Shape mismatch: {len(decoded)} vs {len(targs)}\"\n    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n    import matplotlib.pyplot as plt\n\n    cm = confusion_matrix(targs.cpu(), decoded.cpu())\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=learn.dls.vocab)\n    disp.plot(xticks_rotation=45, cmap='Blues')\n    plt.tight_layout()\n    plt.show()\n\n    print(\"\\nPer-class accuracy:\")\n    cm = confusion_matrix(val_targets, val_predictions.argmax(dim=1))\n    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n    for cls, acc in zip(learn.dls.vocab, per_class_acc):\n        print(f\"{cls}: {acc:.4f}\")\n\n    print(\"Evaluation completed\")\n\n    learn.remove_cb(CSVLogger)\n    learn.export(\"road_quality_classifier.pkl\")\n    print(\"Model saved successfully\")\n\n\nif __name__ == '__main__':\n    multiprocessing.freeze_support()\n    main()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9571c884-6647-4a1e-b591-70f37402e376",
      "cell_type": "markdown",
      "source": "## üîç Detailed Explanation of the `main()` Function\n\nThis function orchestrates the entire model training and evaluation pipeline using the FastAI library. Below is a breakdown of each major step:\n\n---\n\n### üì¶ 1. Data Loading and Transformation\n\n```python\ndls = ImageDataLoaders.from_folder(\n    data_path,\n    train='train',\n    valid='val',\n    valid_pct=None,\n    item_tfms=Resize(224),\n    batch_tfms=aug_transforms(mult=1.5) + [Normalize.from_stats(*imagenet_stats)],\n    bs=64,\n    num_workers=0,\n    shuffle=True\n)\n```\n\nPurpose: Load images from `train/` and `val/` folders and apply preprocessing.\n\n- Resize all images to 224x224\n- Apply image augmentations like flipping, zoom, warp, etc.\n- Normalize with ImageNet statistics\n- Use a batch size of 64\n- Shuffle training data for better generalization\n\n---\n\n### üßÆ 2. Compute Class Counts\n\n```python\ntrain_folder = data_path / 'train'\ntrain_labels = [int(path.parent.name) for path in train_folder.rglob('*') if path.is_file()]\nnum_classes = len(set(train_labels))\ncounts = Counter(train_labels)\nclass_counts = [counts.get(i, 1) for i in range(num_classes)]\n```\n\nPurpose: Count how many training samples exist for each class. This helps to create a balanced loss function so rare classes are not ignored.\n\n- Extract labels from folder names\n- Count number of samples per label\n- Fill in missing classes with count 1 to avoid division by zero\n- Store this in `class_counts`\n\n---\n\n### üß† 3. Create Learner with Custom Loss and Metric\n\n```python\nlearn = vision_learner(dls, resnet50,\n    loss_func=BalancedHybridLoss(class_counts, alpha=0.35),\n    metrics=[\n        accuracy,\n        BalancedLabelDistance()\n    ],\n    cbs=[\n        SaveModelCallback(...),\n        EarlyStoppingCallback(...),\n        ReduceLROnPlateau(...),\n        GradientClip(max_norm=1.0),\n        CSVLogger(fname='training_log.csv')\n    ])\n```\n\nPurpose: Set up the model training configuration using FastAI's Learner.\n\n- `resnet50`: Pretrained model used as a backbone\n- `BalancedHybridLoss`: Custom loss combining cross-entropy and label distance\n- `BalancedLabelDistance`: Custom metric tracking prediction distance from true labels\n- Callbacks:\n  - SaveModelCallback: Save best-performing model\n  - EarlyStoppingCallback: Stop early if no improvement\n  - ReduceLROnPlateau: Lower LR if validation loss stalls\n  - GradientClip: Prevent exploding gradients\n  - CSVLogger: Log metrics to CSV\n\n---\n\n### üîÅ 4. Train and Fine-Tune Model\n\n```python\nlearn.fine_tune(40)\n```\n\nPurpose: Fine-tune the model over 40 epochs. Uses transfer learning.\n\n- First few epochs train the head only\n- Then all layers are unfrozen and trained\n\n---\n\n### üìä 5. Evaluate Overall Accuracy\n\n```python\nval_predictions, val_targets = learn.get_preds()\nval_accuracy = accuracy_score(val_targets, val_predictions.argmax(dim=1))\n```\n\nPurpose: Check how well the model performs overall on validation data.\n\n- `get_preds()` returns predictions and labels\n- `accuracy_score` gives overall classification accuracy\n\n---\n\n### üìè 6. Balanced Label Distance Evaluation\n\nPurpose: Measure the average distance between predicted and actual class indices.\n\n- For example, predicting class 4 when the true label is 5 is less bad than predicting class 1\n- This metric gives a more nuanced view of performance, especially in ordinal problems\n\n---\n\n### üìâ 7. Confusion Matrix and Per-Class Accuracy\n\n```python\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n...\n```\n\nPurpose: Visualize which classes are confused with each other and calculate per-class accuracy.\n\n- Confusion matrix shows counts of true vs predicted labels\n- Per-class accuracy helps identify which labels are hardest to predict\n\n---\n\n### üíæ 8. Export the Trained Model\n\n```python\nlearn.remove_cb(CSVLogger)\nlearn.export(\"road_quality_classifier.pkl\")\n```\n\nPurpose: Save the trained model to disk as a `.pkl` file.\n\n- Can be loaded later for inference\n- Includes model weights, transforms, and label mappings\n\n---\n\n### ‚úÖ Summary\n\n| Step | Purpose |\n|------|---------|\n| Data Loading | Load and preprocess image data |\n| Class Count | Adjust loss to balance rare vs common classes |\n| Learner Setup | Define model, loss, metrics, and training hooks |\n| Training | Fine-tune model using transfer learning |\n| Evaluation | Measure accuracy and custom distance metric |\n| Visualization | See how well each class is recognized |\n| Export | Save trained model for reuse |\n",
      "metadata": {}
    },
    {
      "id": "814c430f-0604-459f-8ca9-eee35fe7fe60",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}